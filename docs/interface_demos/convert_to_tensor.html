
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Convert to Tensor Interface</title>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
  <style>
    body {
      background-color: #1e1e1e;
      color: #ccc;
      font-family: monospace;
      padding: 2rem;
    }
    pre {
      background: #2d2d2d;
      padding: 1rem;
      border-radius: 8px;
      font-size: 14px;
      line-height: 1.5;
      overflow-x: auto;
    }
    .cursor {
      display: inline-block;
      width: 8px;
      height: 1em;
      background: #ccc;
      animation: blink 1s step-start infinite;
      vertical-align: bottom;
      margin-left: -2px;
    }
    @keyframes blink {
      50% { background: transparent; }
    }
  </style>
</head>
<body>
  <h1>Convert to Tensor Interface</h1>
  <pre class="language-python"><code id="code-block"></code><span class="cursor"></span></pre>

  <!-- Prism.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

  <script>
    const rawCode = `import numpy as np
import torch

from omnigenome import OmniGenomeDatasetForTokenRegression

class Dataset(OmniGenomeDatasetForTokenRegression):
    """
    Custom dataset class that inherits from OmniGenomeDatasetForTokenRegression
    """
    def __init__(self, data_source, tokenizer, max_length, **kwargs):
        super().__init__(data_source, tokenizer, max_length, **kwargs)

    # prepare_input: tokenize and align 3D reactivity values
    def prepare_input(self, instance, **kwargs):
        target_cols = ["reactivity", "deg_Mg_pH10", "deg_Mg_50C"]
        instance["sequence"] = f'{instance["sequence"]}'
        tokenized_inputs = self.tokenizer(
            instance["sequence"],
            padding="max_length",
            max_length=self.max_length,
            truncation=True,
            return_tensors="pt",
        )
        labels = [instance[col] for col in target_cols]
        labels = np.concatenate(
            [
                np.array(labels),
                np.array([
                    [-100] * (len(tokenized_inputs["input_ids"].squeeze()) - len(labels[0]))
                ] * 3),
            ],
            axis=1,
        ).T
        tokenized_inputs["labels"] = torch.tensor(labels, dtype=torch.float32)
        for col in tokenized_inputs:
            tokenized_inputs[col] = tokenized_inputs[col].squeeze()
        return tokenized_inputs
    `;
    let i = 0;
    let buffer = "";
    let throttle = 1;
    const codeBlock = document.getElementById("code-block");
    const cursor = document.querySelector(".cursor");

    function typeChar() {
      while (i < rawCode.length && rawCode[i] === ' ') {
        buffer += rawCode[i++];
      }
      if (i < rawCode.length) {
        buffer += rawCode[i++];
        if (i % throttle === 0 || i === rawCode.length) {
          codeBlock.innerHTML = Prism.highlight(buffer, Prism.languages.python, 'python');
        }
        setTimeout(typeChar, 20);
      } else {
        cursor.remove();
        codeBlock.innerHTML = Prism.highlight(buffer, Prism.languages.python, 'python');
      }
    }

    typeChar();
  </script>
</body>
</html>
